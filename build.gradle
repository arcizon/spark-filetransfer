plugins {
    id "idea"
    id "scala"
    id "net.nemerosa.versioning" version "2.14.0"
    id "com.adtran.scala-multiversion-plugin" version "1.0.36"
    id "com.palantir.docker-run" version "0.25.0"
    id "com.github.maiflai.scalatest" version "0.26"
    id "org.scoverage" version "4.0.2"
    id "com.diffplug.gradle.spotless" version "4.5.1"
    id "com.github.johnrengelman.shadow" version "6.0.0"
    id "maven-publish"
    id "signing"
    id "io.codearte.nexus-staging" version "0.22.0"
}

sourceCompatibility = JavaVersion.VERSION_1_8
targetCompatibility = JavaVersion.VERSION_1_8

idea {
    project {
        languageLevel = JavaVersion.VERSION_1_8
        vcs = "Git"
    }
}

scalaMultiVersion {
    scalaVersionPlaceholder = "%scala-version%"
    scalaSuffixPlaceholder = "_%%"
}

repositories {
    mavenCentral()
    jcenter()
}

dependencies {
    implementation "org.scala-lang:scala-library:%scala-version%"
    implementation "com.jcraft:jsch:${jschVersion}"
    shadow "org.apache.spark:spark-sql_%%:${sparkVersion}"

    testImplementation "com.holdenkarau:spark-testing-base_%%:${sparkVersion}_${sparkTestingBaseVersion}"
    testImplementation "org.scalamock:scalamock_%%:${scalaMockVersion}"

    testRuntime "org.pegdown:pegdown:${pegdownVersion}"
}

task cleanTestResources(type: Exec) {
    standardOutput = new ByteArrayOutputStream()

    workingDir = project.rootDir

    commandLine = ['git', 'clean', '-fdx', 'src/test/resources']

    ext.output = {
        return standardOutput.toString()
    }
}

clean {
    dependsOn(cleanTestResources, dockerStop, dockerRemoveContainer)
    delete.addAll(["target/", "derby.log"])
}

task scaladocJar(type: Jar, dependsOn: scaladoc) {
    classifier "javadoc"
    from scaladoc
}

spotless {
    scala {
        scalafmt()
    }
}

jar.enabled = false

shadowJar {
    archiveClassifier.set(null)
    zip64 = true
    manifest {
        attributes(
                'Built-By'       : System.properties['user.name'],
                'Build-Timestamp': new java.text.SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSZ").format(new Date()),
                'Build-Revision' : versioning.info.commit,
                'Created-By'     : "Gradle ${gradle.gradleVersion}",
                'Build-Jdk'      : "${System.properties['java.version']} (${System.properties['java.vendor']} ${System.properties['java.vm.version']})",
                'Build-OS'       : "${System.properties['os.name']} ${System.properties['os.arch']} ${System.properties['os.version']}",
                'Scala-Compiler-Version': scalaVersion
        )
    }
    mergeServiceFiles()
}

test {
    tags {
        exclude "com.github.arcizon.spark.filetransfer.IntegrationTest"
    }
}

dockerRun {
    name "sparkfiletransfer-sftp"
    image "atmoz/sftp"
    volumes "${project.rootDir}/src/test/resources/sftp": "/home/foo/data"
    ports "2222:22"
    daemonize true
    env SFTP_USERS: "foo:pass:1001"
}

dockerRemoveContainer.mustRunAfter(dockerStop)

task integrationTest(type: Test) {
    maxParallelForks = 1
    tags {
        include "com.github.arcizon.spark.filetransfer.IntegrationTest"
    }
    dependsOn(tasks.dockerRun)
    finalizedBy(tasks.dockerStop, tasks.dockerRemoveContainer)
}

scoverage {
    minimumRate.set(0.7)
    excludedPackages.addAll([
            "com.github.arcizon.spark.filetransfer.Driver"
    ])
}

scaladoc {
    title = "Spark File Transfer v${project.version} API"
    scalaDocOptions.setAdditionalParameters([
            "-doc-root-content", "rootdoc.txt",
            "-nowarn",
            "-groups",
            "-implicits"
    ])
}

artifacts {
    archives shadowJar, scaladocJar
}

signing {
    required { gradle.taskGraph.hasTask("publish") }
    sign configurations.archives
}

publishing {
    publications {
        mavenScala(MavenPublication) {
            from components.java
            artifact shadowJar
            artifact scaladocJar

            signArchives.signatures.each { signature ->
                artifact(signature) {
                    extension signature.type
                }
            }

            artifact(file("$buildDir/publications/mavenScala/pom-default.xml.asc")) {
                extension "pom.asc"
                builtBy signArchives
            }

            pom {
                packaging = "jar"
                description = "API for reading and writing data via various file transfer protocols from Apache Spark."
                name = "Spark File Transfer"
                url = "https://github.com/arcizon/spark-filetransfer"
                organization {
                    name = "com.github.arcizon"
                    url = "https://github.com/arcizon"
                }
                issueManagement {
                    system = "GitHub"
                    url = "https://github.com/arcizon/spark-filetransfer/issues"
                }
                scm {
                    url = "https://github.com/arcizon/spark-filetransfer"
                    connection = "scm:git:git://github.com/arcizon/spark-filetransfer.git"
                    developerConnection = "scm:git:ssh://github.com/arcizon/spark-filetransfer.git"
                }
                developers {
                    developer {
                        id = "shaikmanu797"
                        name = "Mansoor Baba Shaik"
                        email = "mansoorbabashaik@outlook.com"
                        url = "https://github.com/shaikmanu797"
                    }
                }
                licenses {
                    license {
                        name = "MIT License"
                        url = "http://opensource.org/licenses/MIT"
                    }
                }
            }
        }
    }
    repositories {
        maven {
            def releasesRepoUrl = "https://oss.sonatype.org/service/local/staging/deploy/maven2/"
            def snapshotsRepoUrl = "https://oss.sonatype.org/content/repositories/snapshots/"
            def envNexusUsername=System.getenv("NEXUS_USERNAME")
            def envNexusPassword=System.getenv("NEXUS_PASSWORD")
            url = version.endsWith("SNAPSHOT") ? snapshotsRepoUrl : releasesRepoUrl
            credentials {
                username = envNexusUsername != null ? envNexusUsername : nexusUsername
                password = envNexusPassword != null ? envNexusPassword : nexusPassword
            }
        }
    }
}

nexusStaging {
}

model {
    tasks.publishMavenScalaPublicationToMavenLocal {
        dependsOn project.tasks.signArchives
    }
    tasks.publishMavenScalaPublicationToMavenRepository {
        dependsOn project.tasks.signArchives
    }

    tasks.generatePomFileForMavenScalaPublication {
        signArchives.dependsOn it
        signArchives.sign it.outputs.files.singleFile
    }
}